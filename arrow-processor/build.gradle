import static org.apache.tools.ant.taskdefs.condition.Os.*

plugins {
    id 'scala'
}

group 'nl.tudelft.nonnenmacher'
version '1.0-SNAPSHOT'

sourceCompatibility = 1.8

repositories {
    mavenCentral()
}

dependencies {
    compile "org.scala-lang:scala-library:$scalaVersion"
    compile "org.scala-lang:scala-reflect:$scalaVersion"
    compile "org.scala-lang:scala-compiler:$scalaVersion"

    compile "org.apache.arrow:arrow-vector:$arrowVersion"


    if (isFamily(FAMILY_MAC)) {
        compile "org.apache.arrow.gandiva:arrow-gandiva:$arrowVersion"
    } else {
        // The arrow gandiva library on central maven only includes the native libraries for MacOs
        // therefore on Linux the self-build version has to be used
        def gandivaJarDir = System.getenv("GANDIVA_JAR_DIR") ?: { throw new Exception("The env variable GANDIVA_JAR_DIR is not set. Cannot find gandiva jar file ") }()
        def gandivaJar = file("$gandivaJarDir/arrow-gandiva-${arrowVersion}.jar")

        if (!gandivaJar.exists()) {
            throw new Exception("Cannot find gandiva jar at \$GANDIVA_JAR_DIR/arrow-gandiva-${arrowVersion}.jar")
        }
        compile files(gandivaJar)

        // transitive dependencies of arrow-gandiva https://mvnrepository.com/artifact/org.apache.arrow.gandiva/arrow-gandiva/0.17.0
        compile "com.google.guava:guava:23.0"

        if (isArch("ppc64le")) {
            // the protobuf version 2.5.0 is not compatible with power systems
            // therefore we changed the version manually and have to use here the same
            compile "com.google.protobuf:protobuf-java:3.7.1"
        } else {
            compile "com.google.protobuf:protobuf-java:2.5.0"
        }
        compile "org.apache.arrow:arrow-memory:$arrowVersion"
        compile "org.apache.arrow:arrow-vector:$arrowVersion"
        compile "org.slf4j:slf4j-api:1.7.25"
    }

    //USE JUnit 4 instead of 5 because scalatest is not compatible with jUni5
    testCompile 'org.scalatest:scalatest_2.12:3.0.1'
    testImplementation('junit:junit:4.13')
}


def libraryPaths = System.getenv("LD_LIBRARY_PATH")?.split(':')?.toList() ?: []
libraryPaths.addAll([file("${project(':arrow-processor-native').buildDir}/lib/main/debug").absolutePath,
                     "/usr/local/lib64",
                     "/usr/local/lib"])

test {
    systemProperty "java.library.path", libraryPaths.join(':')
    systemProperty "io.netty.allocator.directMemoryCacheAlignment", "64"
}

def nativeClasses = ['nl.tudelft.ewi.abs.nonnenmacher.JNIProcessor',
                     'nl.tudelft.ewi.abs.nonnenmacher.MaxIntAggregator',
                     'nl.tudelft.ewi.abs.nonnenmacher.ParquetReaderEvaluator',
                     'nl.tudelft.ewi.abs.nonnenmacher.FletcherProcessor',
                     'nl.tudelft.ewi.abs.nonnenmacher.JNIProcessorFactory$Initializer',
                     'nl.tudelft.ewi.abs.nonnenmacher.NativeParquetReader']

task generateNativeHeaders(type: Exec) {

    dependsOn(compileScala)

    def compileOutput = compileScala.outputs.files[0].getAbsolutePath()

    inputs.files(nativeClasses.collect { "$compileOutput/${it.replace('.', '/')}.class" })
    outputs.dir("$project.buildDir/headers")

    commandLine "$System.env.JAVA_HOME/bin/javah"

    def scalaLibs = "$System.env.SCALA_HOME/lib"

    def dependencies = configurations.runtime.files.collect { it.toPath() }.join(":")

    args('-cp', "$scalaLibs/scala-library.jar:$scalaLibs/scala-reflect.jar:$compileOutput:$dependencies")

    args('-d', outputs.files[0].absolutePath)

    args(nativeClasses)
}

def classesTask = project.getTasksByName('classes', false).head()

project(':arrow-processor-native').afterEvaluate {
    classesTask.dependsOn(project(':arrow-processor-native').assemble)
}